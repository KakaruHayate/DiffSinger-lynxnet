## common layers parallel
内含一个并行的transformer实现用于fastspeech2部分，类似GPT-J，节省了很微小的一点参数

ONNX下的效率会有些许提升，但是训练的稳定性下降
